<!DOCTYPE html>
<!-- saved from url=(0039)http://www.cbsr.ia.ac.cn/users/sfzhang/ -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0">
  <meta name="author" content="yangxue">
  <title>Xue Yang's Homepage</title>

  <!-- CSS  -->
  <link href="./files/materialize.min.css" type="text/css" rel="stylesheet" media="screen,projection">
  <link href="./files/aos.css" type="text/css" rel="stylesheet" media="screen,projection">
  <link href="./files/style.css" type="text/css" rel="stylesheet" media="screen,projection">

  <link rel="shortcut icon" href="./images/yangxue.jpg">
<script type="text/javascript" src="./files/jquery-1.12.4.min.js.ä¸‹è½½"></script><style>@-moz-keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}@-webkit-keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}@-o-keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}@keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}embed,object{animation-duration:.001s;-ms-animation-duration:.001s;-moz-animation-duration:.001s;-webkit-animation-duration:.001s;-o-animation-duration:.001s;animation-name:nodeInserted;-ms-animation-name:nodeInserted;-moz-animation-name:nodeInserted;-webkit-animation-name:nodeInserted;-o-animation-name:nodeInserted;}</style></head>
<body data-aos-easing="ease" data-aos-duration="400" data-aos-delay="0">
  
  <div class="navbar-fixed">

    <nav class="white">
      <div class="nav-wrapper container"><a id="logo-container" href="https://yangxue0827.github.io/#" class="brand-logo"></a>
        <ul class="left">
          <li><a class="nav-item waves-effect waves-light active" href="https://yangxue0827.github.io/#home">Home</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://yangxue0827.github.io/#biography">Biography</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://yangxue0827.github.io/#news">News</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://yangxue0827.github.io/#recent_works">Publications</a></li>
          <!-- <li><a class="nav-item waves-effect waves-light" href="https://yangxue0827.github.io/#preprints">Preprints</a></li> -->
          <li><a class="nav-item waves-effect waves-light" href="https://yangxue0827.github.io/#activities">Activities</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://yangxue0827.github.io/#education">Education</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://yangxue0827.github.io/#internship">Internship</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://yangxue0827.github.io/#awards">Awards</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://yangxue0827.github.io/#projects">Projects</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://yangxue0827.github.io/#friends">Friends</a></li>
        </ul>
        </ul>

      </div>
    </nav>
  </div>
  

<!--==========================================
                   News
===========================================-->
<div class="section news-section scrollspy" id="news">

  <div class="row container">
    <div class="row">
      <div class="title">ğŸ”¥ News</div>
      <hr>
    </div>
    <div class="row">
      <ul>

        <!-- <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 02 / 2024: &nbsp; <font color="red"> Happy Chinese New Year! </font>
        </li> -->

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 09 / 2024: &nbsp; ğŸ‰ğŸ‰ğŸ‰ Three papers related to detection (<b>one Oral</b> and <b>one Spotlight</b>) are accepted by <b>NeurIPS 2024</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 09 / 2024: &nbsp; I'm selected into the <a href="https://elsevier.digitalcommonsdata.com/datasets/btchxktzyw/7">World's Top 2% Scientists 2024 List</a>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 08 / 2024: &nbsp; I will serve as <b>Area Chair</b> for <b>ICLR 2025</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 07 / 2024: &nbsp; Two papers on scene text detection (FreeReal) and open vocabulary detection (CastDet) are accepted by <b>ECCV 2024</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 03 / 2024: &nbsp; <a href="https://mp.weixin.qq.com/s/5nb3je2q1ZHqzL8oDE-YUQ" target="_blank">SJTU Outstanding Doctoral Dissertation</a>, fifteen winners in SJTU <a href="https://www.gs.sjtu.edu.cn/yxbslw">[ä¸Šæµ·äº¤é€šå¤§å­¦ä¼˜ç§€åšå£«å­¦ä½è®ºæ–‡ï¼Œå…¨æ ¡15äºº/å·¥å­¦8äºº]</a>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 02 / 2024: &nbsp; Four papers on oriented object detection, LLM for AI Agent (Minecraft) are accepted by <b>CVPR 2024</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 02 / 2024: &nbsp; One collaborative paper on oriented object detection (ARS-DETR) is accepted by <b>TGRS</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 12 / 2023: &nbsp; I'm awarded the <a href="https://mp.weixin.qq.com/s/Hk8iKReAUJVB_CraXqWYKg" target="_blank">CCF Doctoral Dissertation Award</a>, nine winners in China <a href="https://mp.weixin.qq.com/s/8wLaq2SvYF6zPbf_UFI_XQ">[CCF ä¼˜ç§€åšå£«å­¦ä½è®ºæ–‡æ¿€åŠ±è®¡åˆ’ï¼Œå…¨å›½ä¹äºº]</a>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 12 / 2023: &nbsp; One paper on oriented object detection (AlphaRotate) is accepted by <b>ICASSP 2024</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 11 / 2023: &nbsp; I'm selected into the <a href="https://elsevier.digitalcommonsdata.com/datasets/btchxktzyw/6">World's Top 2% Scientists 2022/2023 List</a>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 10 / 2023: &nbsp; I'm elected as CSIG-BVD Committee Member at PRCV 2023
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 09 / 2023: &nbsp; One paper on oriented object detection (H2RBox-v2) is accepted by <b>NeurIPS 2023</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 07 / 2023: &nbsp; One collaborative paper on self-supervised text recognition (CCD) is accepted by <b>ICCV 2023</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 07 / 2023: &nbsp; Researcher at OpenGVLab, Shanghai AI Laboratory, working with <a href="https://scholar.google.com.hk/citations?user=SH_-B_AAAAAJ&hl=en">Prof. Jifeng Dai</a> 
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 06 / 2023: &nbsp; A report is made at the Valse 2023 Wuxi <a href="http://valser.org/2023/#/workshop" target="_blank">[Valse 2023 æ— é”¡, W2ï¼šé¥æ„Ÿå½±åƒè§£è¯‘]</a>, <a href="./files/VALSE 2023 Wuxi.pdf" target="_blank">[æŠ¥å‘ŠPPT]</a>, <a href="">[æŠ¥å‘Šå›æ”¾]</a> 
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 05 / 2023: &nbsp; I'm awarded the <a href="https://www.seiee.sjtu.edu.cn/xsgz_tzgg_zyfz/7915.html" target="_blank">Shanghai Outstanding Graduates</a> 
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 05 / 2023: &nbsp; Passed the doctoral dissertation defense <a href="https://drive.google.com/file/d/1xEgDcKrW7BeRkDHRX-aXmhUUow2TlfZ2/view?usp=share_link">[dissertation]</a>, <a href="https://drive.google.com/file/d/1uwGQ0AqpYmgg-6bPpLZ22o17sktdk4dL/view?usp=share_link">[slides]</a>, <a href="https://drive.google.com/file/d/1wns-nIUeXifKMJ2EQyhNbKDPpQWjK3wa/view?usp=share_link">[playback]</a> 
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 03 / 2023: &nbsp; Jittor implementation of CSL and RSDet are supported in <a href="https://github.com/Jittor/JDet" target="_blank">JDet</a> <img src="https://img.shields.io/github/stars/Jittor/JDet?style=social" />
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 03 / 2023: &nbsp; A report is made at OpenMMLab <a href="https://mp.weixin.qq.com/s/eoSxS64EtyF8FRMd3BlS-w" target="_blank">[OpenMMLabç¤¾åŒºå¼€æ”¾éº¦]</a>, <a href="./files/OpenMMLabå¼€æ”¾éº¦20230302.pdf" target="_blank">[slides]</a>, <a href="https://www.bilibili.com/video/BV1GD4y1g7s8" target="_blank">[bilibili]</a><img src="https://img.shields.io/badge/dynamic/json?label=views&style=social&logo=bilibili&query=data.stat.view&url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1GD4y1g7s8" />, <a href="https://www.zhihu.com/zvideo/1614738654315995136" target="_blank">[zhihu]</a><img src="https://img.shields.io/badge/dynamic/json?label=views&style=social&logo=zhihu&query=video.play_count&url=https://www.zhihu.com/api/v4/zvideos/1614738654315995136" />
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 02 / 2023: &nbsp; Research internship at OpenGVLab, Shanghai AI Laboratory, working with <a href="https://scholar.google.com.hk/citations?user=SH_-B_AAAAAJ&hl=en">Prof. Jifeng Dai</a>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 02 / 2023: &nbsp; One collaborative paper on text recognition (SIGA) is accepted by <b>CVPR 2023</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 02 / 2023: &nbsp; One paper on oriented object detection is accepted by SCIENTIA SINICA Informationis <a href="http://engine.scichina.com/doi/10.1360/SSI-2022-0410"><b>ã€Šä¸­å›½ç§‘å­¦ï¼šä¿¡æ¯ç§‘å­¦ã€‹</b></a>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 01 / 2023: &nbsp; One collaborative paper on oriented object detection (G-Rep) is accepted by <b>Remote Sensing</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 01 / 2023: &nbsp; Three papers on rotation detection (H2RBox, KFIoU), instance segmentation (PatchDCT) are accepted by <b>ICLR 2023</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 01 / 2023: &nbsp; One collaborative paper on oriented object detection (TIOE) is accepted by <b>ISPRS</b>
        </li>
        
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 12 / 2022: &nbsp; A report is made at the Doctoral Forum of PRCV 2022 <a href="https://m.inmuu.com/v1/live/news/2265574?gatherId=4043" target="_blank">[PRCV 2022 åšå£«ç”Ÿè®ºå›]</a>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 12 / 2022: &nbsp; I'm awarded by the <a href="https://mp.weixin.qq.com/s/mUgpVmyvCHdo5-T6-u8Yxg">CCF-CV Academic Emerging Scholar</a>, three winners in China <a href="https://tc.ccf.org.cn/ccfcv/xgzy/timing/2021-05-04/697856.shtml">[CCF-CV å­¦æœ¯æ–°é”å­¦è€…ï¼Œå…¨å›½ä¸‰äºº]</a>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 11 / 2022: &nbsp; Jittor implementation of GWD, KLD, KFIoU and H2RBox are supported in <a href="https://github.com/Jittor/JDet" target="_blank">JDet</a> <img src="https://img.shields.io/github/stars/Jittor/JDet?style=social" />
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 11 / 2022: &nbsp; One collaborative paper on oriented object detection (PVT-SAR) is accepted by <b>JSTARS</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 09 / 2022: &nbsp; I'm awarded by the <a href="https://mp.weixin.qq.com/s/liVosHsotD2zDMyfmTIQJg" target="_blank">Doctoral National Scholarship</a>
        </li>
        
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 08 / 2022: &nbsp; ğŸ‰ğŸ‰ My <a href="https://scholar.google.com/citations?user=2xTlvV0AAAAJ&hl=en">google scholar</a> citations have exceeded 2000!
        </li>
        
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 08 / 2022: &nbsp; One paper on oriented object detection is accepted by <b>TPAMI</b>
        </li>
        
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 07 / 2022: &nbsp; A report is made at OpenMMLab <a href="https://mp.weixin.qq.com/s/-_x4URDyhwqNC4mD_0daDw" target="_blank">[OpenMMLabç¤¾åŒºå¼€æ”¾éº¦]</a>, <a href="./files/OpenMMLabå¼€æ”¾éº¦.pdf" target="_blank">[slides]</a>, <a href="./files/OpenMMLabå¼€æ”¾éº¦.pdf" target="_blank">[slides]</a>, <a href="https://www.bilibili.com/video/BV1Wr4y1E7Qr" target="_blank">[bilibili]</a><img src="https://img.shields.io/badge/dynamic/json?label=views&style=social&logo=bilibili&query=data.stat.view&url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1Wr4y1E7Qr" />, <a href="https://www.zhihu.com/zvideo/1529579010677370880" target="_blank">[zhihu]</a><img src="https://img.shields.io/badge/dynamic/json?label=views&style=social&logo=zhihu&query=video.play_count&url=https://www.zhihu.com/api/v4/zvideos/1529579010677370880" />
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 06 / 2022: &nbsp; <a href="https://github.com/open-mmlab/mmrotate">MMRotate</a> is accepted by <b>ACM MM 2022</b> as <b>Oral</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 06 / 2022: &nbsp; A report is made at Young Scholars Forum of Wu Wenjun's artificial intelligence doctoral class <a href="https://mp.weixin.qq.com/s/lg1vNIZYqnDfq9SC93OT3A" target="_blank">[å´ç­Talk]</a>, <a href="./files/å´ç­Talk.pdf" target="_blank">[slides]</a>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 06 / 2022: &nbsp; One collaborative paper on oriented object detection (RSDet++) is accepted by <b>TCSVT</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 04 / 2022: &nbsp; One paper on oriented object detection (SCRDet++) is accepted by <b>TPAMI</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 03 / 2022: &nbsp; One collaborative paper on image inpainting is accepted by <b>CVPR 2022</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 02 / 2022: &nbsp; A PyTorch-based oriented object detection benchmark is released, called <a href="https://github.com/open-mmlab/mmrotate">MMRotate</a> <img src="https://img.shields.io/github/stars/open-mmlab/mmrotate?style=social" />
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 02 / 2022: &nbsp; Research internship at EI Innovation Lab, Huawei Cloud, Shanghai, working with <a href="https://scholar.google.com/citations?user=61b6eYkAAAAJ&hl=en">Prof. Qi Tian</a> and <a href="https://scholar.google.com/citations?user=Ud6aBAcAAAAJ&hl=en">Dr. Xiaopeng Zhang</a>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 02 / 2022: &nbsp; One paper on oriented object detection is accepted by <b>IJCV</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 12 / 2021: &nbsp; I'm nominated by <a href="https://mp.weixin.qq.com/s/hr7qtx3OUffSGS9qUhqc9w" target="_blank">SJTU Scholar Star 2021</a>, <a href="https://mp.weixin.qq.com/s/hd7KKoc5u7Wd2R4PdYi-DQ" target="_blank">[ä¸Šæµ·äº¤é€šå¤§å­¦â€œå­¦æœ¯ä¹‹æ˜Ÿâ€æåå¥–]</a>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 12 / 2021: &nbsp; A report is made at the fifth Jittor Forum <a href="https://mp.weixin.qq.com/s/8pYzCYU25B8Zzk78NBoovw" target="_blank">[ç¬¬äº”æœŸâ€œè®¡å›¾â€è®ºå›]</a>, <a href="./files/è®¡å›¾è®ºå›.pdf" target="_blank">[slides]</a>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 10 / 2021: &nbsp; Ranking in the Top 40 in the ninth <a href="./files/baidu_scholarship.jpg" target="_blank">Baidu Scholarship</a>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 09 / 2021: &nbsp; One paper on oriented object detection (KLD) is accepted by <b>NeurIPS 2021</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 09 / 2021: &nbsp; I'm awarded by the <a href="https://mp.weixin.qq.com/s/ugk1l0QpuzJXaExJ_wH-4w" target="_blank">Doctoral National Scholarship (Top-1 in CSE)</a>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 09 / 2021: &nbsp; One collaborative paper on oriented object detection (RIDet) is accepted by <b>GRSL</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 07 / 2021: &nbsp; One collaborative paper on image inpainting is accepted by <b>ICCV 2021</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 07 / 2021: &nbsp; One collaborative paper on oriented object detection (SLA) is accepted by <b>Remote Sensing</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 05 / 2021: &nbsp; A report is made at the Magnolia Young Scholar Forum <a href="https://www.slidestalk.com/w/409" target="_blank">[ç™½ç‰å…°é’å¹´å­¦è€…è®ºå›]</a>, <a href="./files/æ—‹è½¬ç›®æ ‡æ£€æµ‹-ç™½ç‰å…°é’å¹´å­¦è€…è®ºå›.pdf" target="_blank">[slides]</a>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 05 / 2021: &nbsp; One paper on oriented object detection (GWD) is accepted by <b>ICML 2021</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 03 / 2021: &nbsp; One paper on oriented object detection (DCL) is accepted by <b>CVPR 2021</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 12 / 2020: &nbsp; Two papers (one collaborative paper) on oriented object detection (R<sup>3</sup>Det, RSDet) are accepted by <b>AAAI 2021</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 10 / 2020: &nbsp; A TensorFlow-based oriented object detection benchmark is released, called <a href="https://github.com/yangxue0827/RotationDetection">AlphaRotate</a> <img src="https://img.shields.io/github/stars/yangxue0827/RotationDetection?style=social" />
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 10 / 2020: &nbsp; Research internship at EI Innovation Lab, Huawei, Shenzhen, working with <a href="https://scholar.google.com/citations?user=61b6eYkAAAAJ&hl=en">Prof. Qi Tian</a> and <a href="https://scholar.google.com/citations?user=Ud6aBAcAAAAJ&hl=en">Dr. Xiaopeng Zhang</a>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 07 / 2020: &nbsp; One paper on oriented object detection (CSL) is accepted by <b>ECCV 2020</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 09 / 2019: &nbsp; I'm supported by <a href="https://ai.sjtu.edu.cn/info/news/126">Wu Wen Jun Honorary Doctoral Scholarship</a>, AI Institute, Shanghai Jiao Tong University
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 09 / 2019: &nbsp; I'm joining Department of CSE at Shanghai Jiao Tong University as a Ph.D. student, supervised by <a href="http://thinklab.sjtu.edu.cn/">Prof. Junchi Yan</a>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 07 / 2019: &nbsp; One paper on oriented object detection (SCRDet) is accepted by <b>ICCV 2019</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 07 / 2019: &nbsp; One collaborative paper on object detection is accepted by <b>BMVC 2019</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 06 / 2019: &nbsp; We win 1st place in <a href="https://gaia.didichuxing.com/d2city">WAD2019 Challenge</a> on the D<sup>2</sup>-City & BDD100K Detection Domain Adaption track
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 06 / 2019: &nbsp; We win 3st/4th place in <a href="https://captain-whu.github.io/DOAI2019/results.html">DOAI2019 Challenge</a> on the HBB/OBB track 
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 12 / 2018: &nbsp; Research internship at Detection Group, Megvii (Face++) Research, working with <a href="http://www.skicyyu.org/">Dr. Gang Yu</a>
        </li>

      </ul>
    </div>
  </div>
</div>


<!--==========================================
                   Footer
===========================================-->
<footer class="page-footer grey lighten-2">
    <div class="row">
      <div class="widgetContainer" style="width:300px; margin: 0 auto;">        
        <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=080808&w=300&t=tt&d=yZcblN50sSwsCOVmEPYqkPD6Wo-RFHx0E2yb6Ktm_Wk&co=ffffff&ct=808080&cmo=3acc3a&cmn=ff5353'></script>
      </div>
    </div>
    <div class="footer-copyright center black-text">
      Copyright Â© Xue Yang 2020
    </div>  
</footer>

<!--  Scripts-->
<script src="./files/jquery-2.1.1.min.js"></script>
<script src="./files/materialize.js"></script>
<script src="./files/aos.js"></script>
<script src="./init.js"></script>

</div><div class="jvectormap-tip"></div></body></html>