<!DOCTYPE html>
<!-- saved from url=(0039)http://www.cbsr.ia.ac.cn/users/sfzhang/ -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0">
  <meta name="author" content="yangxue">
  <title>Xue Yang's Homepage</title>

  <!-- CSS  -->
  <link href="./files/materialize.min.css" type="text/css" rel="stylesheet" media="screen,projection">
  <link href="./files/aos.css" type="text/css" rel="stylesheet" media="screen,projection">
  <link href="./files/style.css" type="text/css" rel="stylesheet" media="screen,projection">

  <link rel="shortcut icon" href="./images/yangxue.jpg">
<script type="text/javascript" src="./files/jquery-1.12.4.min.js.‰∏ãËΩΩ"></script><style>@-moz-keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}@-webkit-keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}@-o-keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}@keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}embed,object{animation-duration:.001s;-ms-animation-duration:.001s;-moz-animation-duration:.001s;-webkit-animation-duration:.001s;-o-animation-duration:.001s;animation-name:nodeInserted;-ms-animation-name:nodeInserted;-moz-animation-name:nodeInserted;-webkit-animation-name:nodeInserted;-o-animation-name:nodeInserted;}</style></head>
<body data-aos-easing="ease" data-aos-duration="400" data-aos-delay="0">
  
  <div class="navbar-fixed">

    <nav class="white">
      <div class="nav-wrapper container"><a id="logo-container" href="https://yangxue0827.github.io/#" class="brand-logo"></a>
        <ul class="left">
          <li><a class="nav-item waves-effect waves-light active" href="https://yangxue0827.github.io/#home">Home</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://yangxue0827.github.io/#biography">Biography</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://yangxue0827.github.io/#news">News</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://yangxue0827.github.io/#recent_works">Publications</a></li>
          <!-- <li><a class="nav-item waves-effect waves-light" href="https://yangxue0827.github.io/#preprints">Preprints</a></li> -->
          <li><a class="nav-item waves-effect waves-light" href="https://yangxue0827.github.io/#activities">Activities</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://yangxue0827.github.io/#education">Education</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://yangxue0827.github.io/#internship">Internship</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://yangxue0827.github.io/#awards">Awards</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://yangxue0827.github.io/#projects">Projects</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://yangxue0827.github.io/#demos">Demos</a></li>
        </ul>
        </ul>

      </div>
    </nav>
  </div>


<div class="section preprints-section scrollspy" id="summary">

  <div class="row container">
    <div class="row">
      <div class="title">üìù Summary</div>
      <hr>
    </div>
    <div><p><b>Conference</b>: CVPR/ICCV/ECCV (7/3/1), NeurIPS/ICML/ICLR (2/1/3), AAAI (2), ACM MM (1)</p></div>
    <div><p><b>Journal</b>: TPAMI (2), IJCV (1), SCIENTIA SINICA Informationis (1), IEEE Transactions (4)</p></div>
    <div><p><b>Award</b>: ESI Hot Cited Paper (1), ESI Highly Cited Paper (5), Most Influential Paper (2)</p></div>
    <div><font><sup>*</sup> indicates equal contribution, <sup>‚Ä†</sup> indicates corresponding author, <sup>#</sup> indicates project lead</font></div>


  </div>

</div>
  
<!--==========================================
              LLMs and AI Agent
===========================================-->
<div class="section preprints-section scrollspy" id="llms_and_agent">

  <div class="row container">
    <div class="row">
      <div class="title">üìù LLMs and AI Agent</div>
      <hr>
    </div>

    <!-- <div><font color="blue"><b>( <sup>*</sup> indicates equal contribution, <sup>‚Ä†</sup> indicates corresponding author, <sup>#</sup> indicates project lead)</b></font></div><br> -->

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./auto_mc-reward_files/pipeline_v3.png">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">Auto MC-Reward: Automated Dense Reward Design with Large Language Models for Minecraft</div>
        <div class="paper-author">Hao Li<sup>*</sup>, <font color="#0000dd"><b>Xue Yang<sup>*</sup></b></font>, Zhaokai Wang<sup>*</sup>, Xizhou Zhu, Jie Zhou, Yu Qiao, Xiaogang Wang, Hongsheng Li, Lewei Lu, Jifeng Dai<sup>‚Ä†</sup></div>
        <div class="paper-conf">In <em>Proceedings of the IEEE Computer Vision and Pattern Recognition <font color="red"><b>(CVPR, CCF-A)</b></font></em>, Seattle WA, USA, 2024</div>
        <div>
          <a href="https://arxiv.org/abs/2312.09238" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2312.09238-B31B1B.svg" /></a>
          <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:ldfaerwXgEUC" target="_blank">
          <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:ldfaerwXgEUC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:ldfaerwXgEUC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
        </div>
        <div>
            <img class="responsive-img icon" src="./images/homepage.png">
            <a href="./auto_mc-reward.html" target="_blank">[project page]</a>
        </div>
      </div>
    </div>

    <hr class="publication-hr">

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/iGPT.png">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">InternGPT: Solving Vision-Centric Tasks by Interacting with ChatGPT Beyond Language</div>
        <div class="paper-author">Zhaoyang Liu<sup>*</sup>, Yinan He<sup>*</sup>, Wenhai Wang<sup>*</sup>, Weiyun Wang<sup>*</sup>, Yi Wang<sup>*</sup>, Shoufa Chen<sup>*</sup>, Qinglong Zhang<sup>*</sup>, Yang Yang, Qingyun Li, Jiashuo Yu, Kunchang Li, Zhe Chen, <font color="#0000dd"><b>Xue Yang</b></font>, Xizhou Zhu, Yali Wang, Limin Wang, Ping Luo, Jifeng Dai, Yu Qiao</div>
        <div>
          <a href="https://arxiv.org/abs/2305.05662" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2305.05662-B31B1B.svg" /></a>
          <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:RGFaLdJalmkC" target="_blank">
          <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:RGFaLdJalmkC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:RGFaLdJalmkC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
        </div>
        <div>
          <img src="https://img.shields.io/github/stars/OpenGVLab/InternGPT?style=social" />
          <a href="https://github.com/OpenGVLab/InternGPT" target="_blank">[InternGPT]</a>
        </div>
        <div>
          <img class="responsive-img icon" src="./images/mp4.png">
          <a href="https://igpt.opengvlab.com/" target="_blank">[Demo]</a>
        </div>
      </div>
  </div>

  <hr class="publication-hr">



  </div>

</div>

<!--==========================================
        Oriented Object Detection
===========================================-->
<div class="section publications-section scrollspy" id="ood">

  <div class="row container">
    <div class="row">
      <div class="title">üìù Oriented Object Detection</div>
      <hr>
    </div>

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/cobb.png">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">Theoretically Achieving Continuous Representation of Oriented Bounding Boxes</div>
          <div class="paper-author">Zikai Xiao, Guoye Yang, <font color="#0000dd"><b>Xue Yang</b></font>, Taijiang Mu<sup>‚Ä†</sup>, Junchi Yan, Shimin Hu</div>
          <div class="paper-conf">In <em>Proceedings of the IEEE Computer Vision and Pattern Recognition <font color="red"><b>(CVPR, CCF-A)</b></font></em>, Seattle WA, USA, 2024</div>
          <div>
            <a href="https://arxiv.org/abs/2402.18975" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2402.18975-B31B1B.svg" /></a>
            <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:M05iB0D1s5AC" target="_blank">
            <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:M05iB0D1s5AC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:M05iB0D1s5AC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
          </div>
          <div>
            <img src="https://img.shields.io/github/stars/open-mmlab/mmrotate?style=social" />
            <a href="https://github.com/Jittor/JDet" target="_blank">[JDet]</a>
          </div>
        </div>
    </div>

    <hr class="publication-hr">

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/point2rbox.png">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">Point2RBox: Combine Knowledge from Synthetic Visual Patterns for End-to-end Oriented Object Detection with Single Point Supervision</div>
        <div class="paper-author">Yi Yu<sup>*</sup>, <font color="#0000dd"><b>Xue Yang</b><sup>*</sup></font>, Qingyun Li, Feipeng Da<sup>‚Ä†</sup>, Jifeng Dai, Yu Qiao, Junchi Yan<sup>‚Ä†</sup></div>
        <div class="paper-conf">In <em>Proceedings of the IEEE Computer Vision and Pattern Recognition <font color="red"><b>(CVPR, CCF-A)</b></font></em>, Seattle WA, USA, 2024</div>
        <div>
          <a href="https://arxiv.org/abs/2311.14758" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2311.14758-B31B1B.svg" /></a>
          <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:2P1L_qKh6hAC" target="_blank">
          <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:2P1L_qKh6hAC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:2P1L_qKh6hAC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
        </div>
        <div>
          <img src="https://img.shields.io/github/stars/open-mmlab/mmrotate?style=social" />
          <a href="https://github.com/open-mmlab/mmrotate" target="_blank">[Point2RBox-MMRotate]</a>
        </div>
        <div>
          <img class="responsive-img icon" src="./images/zhihu.png">
          <a href="https://zhuanlan.zhihu.com/p/668627776" target="_blank">[Ëß£ËØª]</a>
        </div>
      </div>
    </div>

    <hr class="publication-hr">

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/pointobb.png">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">PointOBB: Learning Oriented Object Detection via Single Point Supervision</div>
        <div class="paper-author">Junwei Luo, <font color="#0000dd"><b>Xue Yang</b><sup>#</sup></font>, Yu Yi, Qingyun Li, Junchi Yan, Yansheng Li<sup>‚Ä†</sup></div>
        <div class="paper-conf">In <em>Proceedings of the IEEE Computer Vision and Pattern Recognition <font color="red"><b>(CVPR, CCF-A)</b></font></em>, Seattle WA, USA, 2024</div>
        <div>
          <a href="https://arxiv.org/abs/2311.14757" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2311.14757-B31B1B.svg" /></a>
          <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:70eg2SAEIzsC" target="_blank">
          <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:70eg2SAEIzsC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:70eg2SAEIzsC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
        </div>
        <div>
          <img src="https://img.shields.io/github/stars/Luo-Z13/pointobb?style=social" />
          <a href="https://github.com/Luo-Z13/pointobb" target="_blank">[PointOBB-Pytorch]</a>
        </div>
        <div>
          <img class="responsive-img icon" src="./images/zhihu.png">
          <a href="https://zhuanlan.zhihu.com/p/668792405" target="_blank">[Ëß£ËØª]</a>
        </div>
      </div>
    </div>

    <hr class="publication-hr">

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/ars-detr.png">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">ARS-DETR: Aspect Ratio Sensitive Oriented Object Detection with Transformer</div>
        <div class="paper-author">Ying Zeng, Yushi Chen<sup>‚Ä†</sup>, <font color="#0000dd"><b>Xue Yang</b></font>, Qingyun Li, Junchi Yan</div>
        <div class="paper-conf"><em>IEEE Transactions on Geoscience and Remote Sensin <font color="red"><b>(TGRS, CCF-B)</b></font></em>, 2024</div> 
        <div>
          <a href="https://arxiv.org/abs/2303.04989" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2303.04989-B31B1B.svg" /></a>
          <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:BqipwSGYUEgC" target="_blank">
          <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:BqipwSGYUEgC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:BqipwSGYUEgC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
        </div>
        <div>
          <img src="https://img.shields.io/github/stars/httle/ARS-DETR?style=social" />
          <a href="https://github.com/httle/ARS-DETR" target="_blank">[ARS-DETR-PyTorch]</a>
        </div>
      </div>
    </div>

    <hr class="publication-hr">

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/projects.png">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">AlphaRotate: A Rotation Detection Benchmark using TensorFlow</div>
          <div class="paper-author"><font color="#0000dd"><b>Xue Yang</b></font>, Yue Zhou, Wenlong Liao, Tao He, Junchi Yan<sup>‚Ä†</sup></div>
          <div class="paper-conf">In <em>Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing <font color="red"><b>(ICASSP, CCF-B)</b></font></em>, Seoul, Korea, 2024</div>
          <div>
            <a href="https://arxiv.org/abs/2111.06677" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2111.06677-B31B1B.svg" /></a>
            <!-- <a href="https://www.semanticscholar.org/paper/AlphaRotate%3A-A-Rotation-Detection-Benchmark-using-Yang-Zhou/7f150cebfbdd2c3a8901a27641f308b34858ea80" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citations&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F7f150cebfbdd2c3a8901a27641f308b34858ea80%3Ffields%3DcitationCount" /></a> -->
            <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:dhFuZR0502QC" target="_blank">
            <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:dhFuZR0502QC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:dhFuZR0502QC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/docs.png">
            <a href="https://rotationdetection.readthedocs.io/" target="_blank">[docs]</a>
          </div>
          <div>
            <img src="https://img.shields.io/github/stars/yangxue0827/RotationDetection?style=social" />
            <a href="https://github.com/yangxue0827/RotationDetection" target="_blank">[AlphaRotate-TF]</a>
          </div>
        </div>
      </div>

      <hr class="publication-hr">
    

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/p2rbox.png">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">P2RBox: A Single Point is All You Need for Oriented Object Detection</div>
        <div class="paper-author">Guangming Cao<sup>*</sup>, Xuehui Yu<sup>*</sup>, Wenwen Yu, Xumeng Han, <font color="#0000dd"><b>Xue Yang</b></font>, Guorong Li, Jianbin Jiao, Zhenjun Han<sup>‚Ä†</sup></div>
        <div>
          <a href="https://arxiv.org/abs/2311.13128" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2311.13128-B31B1B.svg" /></a>
          <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:35N4QoGY0k4C" target="_blank">
          <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:35N4QoGY0k4C' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:35N4QoGY0k4C' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
        </div>
      </div>
    </div>

    <hr class="publication-hr">

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/h2rbox-v2.png">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">H2RBox-v2: Incorporating Symmetry for Boosting Horizontal Box Supervised Oriented Object Detection</div>
        <div class="paper-author">Yi Yu<sup>*</sup>, <font color="#0000dd"><b>Xue Yang<sup>*</sup></b></font>, Qingyun Li, Yue Zhou, Gefan Zhang, Feipeng Da<sup>‚Ä†</sup>, Junchi Yan<sup>‚Ä†</sup></div>
        <div class="paper-conf"><em>Advances in Neural Information Processing Systems <font color="red"><b>(NeurIPS, CCF-A)</b></font></em>, New Orleans, Louisiana, USA, 2023</div> 
        <div>
          <a href="https://arxiv.org/abs/2304.04403" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2304.04403-B31B1B.svg" /></a>
          <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:ns9cj8rnVeAC" target="_blank">
          <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:ns9cj8rnVeAC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:ns9cj8rnVeAC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
        </div>
        <div>
          <img src="https://img.shields.io/github/stars/open-mmlab/mmrotate?style=social" />
          <a href="https://github.com/open-mmlab/mmrotate" target="_blank">[H2RBox-v2-MMRotate]</a>
        </div>
        <div>
          <img class="responsive-img icon" src="./images/zhihu.png">
          <a href="https://zhuanlan.zhihu.com/p/620884206" target="_blank">[Ëß£ËØª]</a>
        </div>
      </div>
  </div>

  <hr class="publication-hr">

    <div class="row">
          <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <img class="responsive-img" src="./images/g-rep.png">
          </div>

          <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <div class="paper-title">G-Rep: Gaussian Representation for Arbitrary-Oriented Object Detection</div>
            <div class="paper-author">Liping Hou, Ke Lu, <font color="#0000dd"><b>Xue Yang</b></font>, Yuqiu Li, Jian Xue<sup>‚Ä†</sup></div>
            <div class="paper-conf">In <em>Remote Sensing</em>, 2023</div>
            <div>
              <a href="https://arxiv.org/abs/2205.11796" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2205.11796-B31B1B.svg" /></a>
              <!-- <a href="https://www.semanticscholar.org/paper/G-Rep%3A-Gaussian-Representation-for-Object-Detection-Hou-Lu/1fd0d6280fcf5ad1ce960b882cde5cad8eb0aa1d" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citations&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F1fd0d6280fcf5ad1ce960b882cde5cad8eb0aa1d%3Ffields%3DcitationCount" /></a> -->
              <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:NMxIlDl6LWMC" target="_blank">
              <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:NMxIlDl6LWMC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:NMxIlDl6LWMC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
            </div>
            <div>
              <img class="responsive-img icon" src="./images/pdf.png">
              <a href="https://www.mdpi.com/2072-4292/15/3/757" target="_blank">[paper]</a>
            </div>
            <!-- <div>
              <img src="https://img.shields.io/github/stars/open-mmlab/mmrotate?style=social" />
              <a href="https://github.com/open-mmlab/mmrotate" target="_blank">[G-Rep-PyTorch]</a>
            </div> -->
          </div>
      </div>

      <hr class="publication-hr">

    <div class="row">
          <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <img class="responsive-img" src="./images/h2rbox.png">
          </div>

          <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <div class="paper-title">H2RBox: Horizontal Box Annotation is All You Need for Oriented Object Detection</div>
            <div class="paper-author"><font color="#0000dd"><b>Xue Yang</b></font>, Gefan Zhang, Wentng Li, Xuehui Wang, Yue Zhou, Junchi Yan<sup>‚Ä†</sup></div>
            <div class="paper-conf">In <em>International Conference on Learning Representations <font color="red"><b>(ICLR, Tsinghua-A)</b></font></em>, Kigali, Rwanda, 2023</div>
            <div>
              <a href="https://arxiv.org/abs/2210.06742" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2210.06742-B31B1B.svg" /></a>
              <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:maZDTaKrznsC" target="_blank">
              <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:maZDTaKrznsC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:maZDTaKrznsC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
            </div>
            <div>
              <img src="https://img.shields.io/github/stars/yangxue0827/h2rbox-mmrotate?style=social" />
              <a href="https://github.com/yangxue0827/h2rbox-mmrotate" target="_blank">[H2RBox-PyTorch], </a>
              <img src="https://img.shields.io/github/stars/open-mmlab/mmrotate?style=social" />
              <a href="https://github.com/open-mmlab/mmrotate" target="_blank">[H2RBox-MMRotate]</a>
            </div>
            <div>
              <img src="https://img.shields.io/github/stars/yangxue0827/h2rbox-jittor?style=social" />
              <a href="https://github.com/yangxue0827/h2rbox-jittor" target="_blank">[H2RBox-Jittor], </a>
              <img src="https://img.shields.io/github/stars/Jittor/JDet?style=social" />
              <a href="https://github.com/Jittor/JDet" target="_blank">[H2RBox-JDet]</a>
            </div>
            <div>
              <img class="responsive-img icon" src="./images/zhihu.png">
              <a href="https://zhuanlan.zhihu.com/p/574337609" target="_blank">[Ëß£ËØª], </a>
              <img src="https://img.shields.io/badge/dynamic/json?label=views&style=social&logo=zhihu&query=video.play_count&url=https://www.zhihu.com/api/v4/zvideos/1614738654315995136" />
              <a href="https://www.zhihu.com/zvideo/1614738654315995136" target="_blank">[Áü•‰πéËßÜÈ¢ëËß£ËØª]</a>
            </div>
            <div>
              <img src="https://img.shields.io/badge/dynamic/json?label=views&style=social&logo=bilibili&query=data.stat.view&url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1GD4y1g7s8" />
              <a href="https://www.bilibili.com/video/BV1GD4y1g7s8" target="_blank">[BÁ´ôËßÜÈ¢ëËß£ËØª]</a>
            </div>
          </div>
      </div>

      <hr class="publication-hr">

      <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/kfiou.png">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">The KFIoU Loss for Rotated Object Detection</div>
          <div class="paper-author"><font color="#0000dd"><b>Xue Yang</b></font>, Yue Zhou, Gefan Zhang, Jirui Yang, Wentao Wang, Junchi Yan<sup>‚Ä†</sup>, Xiaopeng Zhang, Qi Tian</div>
          <div class="paper-conf">In <em>International Conference on Learning Representations <font color="red"><b>(ICLR, Tsinghua-A)</b></font></em>, Kigali, Rwanda, 2023</div>

          <div>
            <a href="https://arxiv.org/abs/2201.12558" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2201.12558-B31B1B.svg" /></a>
            <!-- <a href="https://www.semanticscholar.org/paper/The-KFIoU-Loss-for-Rotated-Object-Detection-Yang-Zhou/be046653174b9e14c29387ed8e8168ae81c9b5c1" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fbe046653174b9e14c29387ed8e8168ae81c9b5c1%3Ffields%3DcitationCount" /></a> -->
            <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:-f6ydRqryjwC" target="_blank">
            <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:-f6ydRqryjwC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:-f6ydRqryjwC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
          </div>
          <div>
            <img src="https://img.shields.io/github/stars/yangxue0827/RotationDetection?style=social" />
            <a href="https://github.com/yangxue0827/RotationDetection" target="_blank">[KFIoU-TF], </a>
            <img src="https://img.shields.io/github/stars/open-mmlab/mmrotate?style=social" />
            <a href="https://github.com/open-mmlab/mmrotate" target="_blank">[KFIoU-PyTorch], </a>
            <img src="https://img.shields.io/github/stars/Jittor/JDet?style=social" />
            <a href="https://github.com/Jittor/JDet" target="_blank">[KFIoU-Jittor]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/zhihu.png">
            <a href="https://zhuanlan.zhihu.com/p/463496550" target="_blank">[Ëß£ËØª]</a>
          </div>
        </div>
      </div>

      <hr class="publication-hr">

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/tioe.jpeg">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">Task Interleaving and Orientation Estimation for High-Precision Oriented Object Detection in Aerial Images</div>
          <div class="paper-author">Qi Ming, Lingjuan Miao, Zhiqiang Zhou<sup>‚Ä†</sup>, Junjie Song, Yunpeng Dong, <font color="#0000dd"><b>Xue Yang</b></font></div>
          <div class="paper-conf"><em>ISPRS Journal of Photogrammetry and Remote Sensing <font color="red"><b>(ISPRS)</b></font></em>, 2023</div>
          <div>
            <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&cstart=20&pagesize=80&citation_for_view=2xTlvV0AAAAJ:blknAaTinKkC" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:blknAaTinKkC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:blknAaTinKkC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
          </div>
          <div class="paper-award">
            <img class="responsive-img icon" src="./images/cup.png">
            <a href="http://apps.webofknowledge.com/"><em><font color="red"><b>ESI Highly Cited Paper</b></font></em></a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/pdf.png">
            <a href="https://www.sciencedirect.com/science/article/pii/S0924271623000011" target="_blank">[paper]</a>
          </div>
          <div>
            <img src="https://img.shields.io/github/stars/ming71/TIOE?style=social" />
            <a href="https://github.com/ming71/TIOE" target="_blank">[TIOE-PyTorch], </a>
          </div>
        </div>
      </div>

      <hr class="publication-hr">

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/PVT-SAR.png">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">PVT-SAR: An Arbitrarily Oriented SAR Ship Detector with Pyramid Vision Transformer</div>
          <div class="paper-author">Yue Zhou, Xue Jiang<sup>‚Ä†</sup>, Guozheng Xu, <font color="#0000dd"><b>Xue Yang</b></font>, Xingzhao Liu</div>
          <div class="paper-conf"><em>IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing <font color="red"><b>(JSTARS)</b></font></em>, 2022</div>
          <div>
            <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&cstart=20&pagesize=80&citation_for_view=2xTlvV0AAAAJ:M3NEmzRMIkIC" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:M3NEmzRMIkIC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:M3NEmzRMIkIC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/pdf.png">
            <a href="https://ieeexplore.ieee.org/document/9947220" target="_blank">[paper]</a>
          </div>
        </div>
      </div>

      <hr class="publication-hr">

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/gaussian.png">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">Detecting Rotated Objects as Gaussian Distributions and Its 3-D Generalization</div>
          <div class="paper-author"><font color="#0000dd"><b>Xue Yang</b></font>, Gefan Zhang, Xiaojiang Yang, Yue Zhou, Wentao Wang, Jin Tang, Tao He, Junchi Yan<sup>‚Ä†</sup></div>
          <div class="paper-conf"><em>IEEE Transactions on Pattern Analysis and Machine Intelligence <font color="red"><b>(TPAMI, CCF-A)</b></font></em>, 2022</div> 
          <div>
              <a href="https://arxiv.org/abs/2209.10839" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2209.10839-B31B1B.svg" /></a>
              <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:vV6vV6tmYwMC" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:vV6vV6tmYwMC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:vV6vV6tmYwMC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
          </div>
          <div class="paper-award">
            <img class="responsive-img icon" src="./images/cup.png">
            <a href="http://apps.webofknowledge.com/"><em><font color="red"><b>ESI Highly Cited Paper</b></font></em></a>
          </div>
          <!-- <div> -->
            <!-- <a href="https://yangxue0827.github.io/" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3Acoming.soon-B31B1B.svg" /></a> -->
            <!-- <img class="responsive-img icon" src="./images/pdf.png"> -->
            <!-- <a href="https://ieeexplore.ieee.org/document/9852282" target="_blank">[paper]</a> -->
          <!-- </div> -->
          <div>
            <img src="https://img.shields.io/github/stars/yangxue0827/RotationDetection?style=social" />
            <a href="https://github.com/yangxue0827/RotationDetection" target="_blank">[AlphaRotate], </a>
            <img src="https://img.shields.io/github/stars/open-mmlab/mmrotate?style=social" />
            <a href="https://github.com/open-mmlab/mmrotate" target="_blank">[MMRotate], </a>
            <img src="https://img.shields.io/github/stars/zhanggefan/mmdet3d-gaussian?style=social" />
            <a href="https://github.com/zhanggefan/mmdet3d-gaussian" target="_blank">[mmdet3d-gaussian], </a>
            <img src="https://img.shields.io/github/stars/Jittor/JDet?style=social" />
            <a href="https://github.com/Jittor/JDet" target="_blank">[JDet]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/zhihu.png">
            <a href="https://zhuanlan.zhihu.com/p/372357305" target="_blank">[GWDËß£ËØª], </a>
            <a href="https://zhuanlan.zhihu.com/p/380016283" target="_blank">[KLDËß£ËØª], </a>
            <img src="https://img.shields.io/badge/dynamic/json?label=views&style=social&logo=zhihu&query=video.play_count&url=https://www.zhihu.com/api/v4/zvideos/1529579010677370880" />
            <a href="https://www.zhihu.com/zvideo/1529579010677370880" target="_blank">[Áü•‰πéËßÜÈ¢ëËß£ËØª]</a>
          </div>
          <div>
            <!-- <img class="responsive-img icon" src="./images/bilibili.png"> -->
            <img src="https://img.shields.io/badge/dynamic/json?label=views&style=social&logo=bilibili&query=data.stat.view&url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1Wr4y1E7Qr" />
            <a href="https://www.bilibili.com/video/BV1Wr4y1E7Qr" target="_blank">[ËßÜÈ¢ëËß£ËØª]</a>
          </div>
        </div>
      </div>

      <hr class="publication-hr">


    <div class="row">
          <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <img class="responsive-img" src="./images/mmrotate.png">
          </div>

          <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <div class="paper-title">MMRotate: A Rotated Object Detection Benchmark using PyTorch</div>
            <div class="paper-author">Yue Zhou<sup>*</sup>, <font color="#0000dd"><b>Xue Yang<sup>*</sup></b></font>, Gefan Zhang, Jiabao Wang, Yanyi Liu, Liping Hou, Xue Jiang<sup>‚Ä†</sup>, Xingzhao Liu, Junchi Yan<sup>‚Ä†</sup>, Chengqi Lyu, Wenwei Zhang, Kai Chen</div>
            <div class="paper-conf">In <em>Proceedings of the 30th ACM International Conference on Multimedia <font color="red"><b>(ACM MM, CCF-A)</b></font></em>, Lisboa, Portugal, Open Source Software Competition, <font color="red"><b>Oral</b></font>, 2022</div> 
            <div>
              <a href="https://arxiv.org/abs/2204.13317" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2204.13317-B31B1B.svg" /></a>
              <!-- <a href="https://www.semanticscholar.org/paper/MMRotate%3A-A-Rotated-Object-Detection-Benchmark-Zhou-Yang/3df973b157132c46f299787d2c5852059d6ce68b" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citations&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F3df973b157132c46f299787d2c5852059d6ce68b%3Ffields%3DcitationCount" /></a> -->
              <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:_Qo2XoVZTnwC" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:_Qo2XoVZTnwC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:_Qo2XoVZTnwC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
            </div>
            <div>
              <img src="https://img.shields.io/github/stars/open-mmlab/mmrotate?style=social" />
              <a href="https://github.com/open-mmlab/mmrotate" target="_blank">[MMRotate]</a>
            </div>
            <div>
              <img class="responsive-img icon" src="./images/mp4.png">
              <a href="https://dl.acm.org/action/downloadSupplement?doi=10.1145%2F3503161.3548541&file=MM22-mmos06.mp4&download=true" target="_blank">[Video]</a>
            </div>
          </div>
      </div>

      <hr class="publication-hr">

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/rsdet++.jpg">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">RSDet++: Point-based Modulated Loss for More Accurate Rotated Object Detection</div>
          <div class="paper-author">Wen Qian, <font color="#0000dd"><b>Xue Yang</b></font>, Silong Peng<sup>‚Ä†</sup>, Junchi Yan, Xiujuan Zhang</div>
          <div class="paper-conf"><em>IEEE Transactions on Circuits and Systems for Video Technology <font color="red"><b>(TCSVT, CCF-B)</b></font></em>, 2022</div>

          <!-- <div> -->
            <!-- <img class="responsive-img icon" src="./images/pdf.png"> -->
            <!-- <a href="https://arxiv.org/abs/1911.08299" target="_blank">paper</a> -->
          <!-- </div> -->
          <div>
            <!-- <img class="responsive-img icon" src="./images/pdf.png"> -->
            <a href="https://arxiv.org/abs/2109.11906" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2109.11906-B31B1B.svg" /></a>
            <!-- <a href="https://www.semanticscholar.org/paper/RSDet%2B%2B%3A-Point-based-Modulated-Loss-for-More-Object-Qian-Yang/abb919ba0e98dfb64fb5f0b7556bf859da867dc6" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citations&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fabb919ba0e98dfb64fb5f0b7556bf859da867dc6%3Ffields%3DcitationCount" /></a> -->
            <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&cstart=20&pagesize=80&citation_for_view=2xTlvV0AAAAJ:4DMP91E08xMC" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:4DMP91E08xMC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:4DMP91E08xMC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
          </div>
          <div>
            <!-- <img class="responsive-img icon" src="./images/github.png"> -->
            <img src="https://img.shields.io/github/stars/yangxue0827/RotationDetection?style=social" />
            <a href="https://github.com/yangxue0827/RotationDetection" target="_blank">[RSDet++-TF]</a>
          </div>
        </div>
      </div>

      <hr class="publication-hr">

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/scrdet++.png">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">SCRDet++: Detecting Small, Cluttered and Rotated Objects via Instance-Level Feature Denoising and Rotation Loss Smoothing</div>
          <div class="paper-author"><font color="#0000dd"><b>Xue Yang</b></font>, Junchi Yan<sup>‚Ä†</sup>, Wenlong Liao, Xiaokang Yang, Jin Tang, Tao He</div>
          <div class="paper-conf"><em>IEEE Transactions on Pattern Analysis and Machine Intelligence <font color="red"><b>(TPAMI, CCF-A)</b></font></em>, 2022</div> 

          <div>
            <!-- <img class="responsive-img icon" src="./images/pdf.png"> -->
            <a href="https://arxiv.org/abs/2004.13316" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2004.13316-B31B1B.svg" /></a>
            <!-- <a href="https://www.semanticscholar.org/paper/SCRDet%2B%2B%3A-Detecting-Small%2C-Cluttered-and-Rotated-Yang-Yan/881bb1d8062529a8a6e42b85345ce99f6bf93175" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citations&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F881bb1d8062529a8a6e42b85345ce99f6bf93175%3Ffields%3DcitationCount" /></a> -->
            <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:lSLTfruPkqcC" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:lSLTfruPkqcC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:lSLTfruPkqcC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
          </div>
          <div class="paper-award">
            <img class="responsive-img icon" src="./images/cup.png">
            <a href="http://apps.webofknowledge.com/"><em><font color="red"><b>ESI Hot Cited Paper, ESI Highly Cited Paper</b></font></em></a>
          </div>  
          <div>
            <!-- <img class="responsive-img icon" src="./images/github.png"> -->
            <img src="https://img.shields.io/github/stars/DetectionTeamUCAS/RetinaNet_Tensorflow_Rotation?style=social" />
            <a href="https://github.com/DetectionTeamUCAS/RetinaNet_Tensorflow_Rotation" target="_blank">[IoU-Smooth L1 Loss-TF], </a>
            <img src="https://img.shields.io/github/stars/SJTU-Thinklab-Det/DOTA-DOAI?style=social" />
            <a href="https://github.com/SJTU-Thinklab-Det/DOTA-DOAI" target="_blank">[DOTA-DOAI]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/dataset2.jpeg">
            <a href="https://github.com/Thinklab-SJTU/S2TLD" target="_blank">[S<sup>2</sup>TLD]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/homepage.png">
            <a href="./SCRDet++.html" target="_blank">[project page]</a>
          </div>
        </div>
      </div>

      <hr class="publication-hr">

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/csl_gcl_ohdet.png">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">On the Arbitrary-Oriented Object Detection: Classification based Approaches Revisited</div>
          <div class="paper-author"><font color="#0000dd"><b>Xue Yang</b></font>, Junchi Yan<sup>‚Ä†</sup></div>
          <div class="paper-conf"><em>International Journal of Computer Vision <font color="red"><b>(IJCV, CCF-A)</b></font></em>, 2022</div> 

          <div>
            <a href="https://arxiv.org/abs/2003.05597" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2003.05597-B31B1B.svg" /></a>
            <!-- <a href="https://www.semanticscholar.org/paper/On-the-Arbitrary-Oriented-Object-Detection%3A-Based-Yang-Yan/94e1b0fe4f00831e8afacc9bf684f1dc8ce39a77" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citations&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F94e1b0fe4f00831e8afacc9bf684f1dc8ce39a77%3Ffields%3DcitationCount" /></a> -->
            <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:RHpTSmoSYBkC" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:RHpTSmoSYBkC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:RHpTSmoSYBkC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
          </div>
          <div>
            <!-- <img class="responsive-img icon" src="./images/github.png"> -->
            <img src="https://img.shields.io/github/stars/Thinklab-SJTU/CSL_RetinaNet_Tensorflow?style=social" />
            <a href="https://github.com/Thinklab-SJTU/CSL_RetinaNet_Tensorflow" target="_blank">[CSL-TF], </a>
            <img src="https://img.shields.io/github/stars/Thinklab-SJTU/DCL_RetinaNet_Tensorflow?style=social" />
            <a href="https://github.com/Thinklab-SJTU/DCL_RetinaNet_Tensorflow" target="_blank">[DCL-TF], </a>
            <img src="https://img.shields.io/github/stars/SJTU-Thinklab-Det/OHDet_Tensorflow?style=social" />
            <a href="https://github.com/SJTU-Thinklab-Det/OHDet_Tensorflow" target="_blank">[OHDet-TF]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/dataset2.jpeg">
            <a href="OHD-SJTU.html" target="_blank">[OHD-SJTU]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/homepage.png">
            <a href="./CSL_GCL_OHDet.html" target="_blank">[project page]</a>
          </div>
        </div>
      </div>

      <hr class="publication-hr">

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/kld.png">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">Learning High-Precision Bounding Box for Rotated Object Detection via Kullback-Leibler Divergence</div>
          <div class="paper-author"><font color="#0000dd"><b>Xue Yang</b></font>, Xiaojiang Yang, Jirui Yang, Qi Ming, Wentao Wang, Qi Tian, Junchi Yan<sup>‚Ä†</sup></div>
          <div class="paper-conf"><em>Advances in Neural Information Processing Systems <font color="red"><b>(NeurIPS, CCF-A)</b></font></em>, Virtual, 2021</div> 

          <div>
            <!-- <img class="responsive-img icon" src="./images/pdf.png"> -->
            <a href="https://arxiv.org/abs/2106.01883" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2106.01883-B31B1B.svg" /></a>
            <!-- <a href="https://www.semanticscholar.org/paper/Learning-High-Precision-Bounding-Box-for-Rotated-Yang-Yang/81150a2746b1696482ca6fa7157e71b82c7ff530" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citations&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F81150a2746b1696482ca6fa7157e71b82c7ff530%3Ffields%3DcitationCount" /></a> -->
            <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:hC7cP41nSMkC" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:hC7cP41nSMkC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:hC7cP41nSMkC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
          </div>
          <div>
            <img src="https://img.shields.io/github/stars/yangxue0827/RotationDetection?style=social" />
            <a href="https://github.com/yangxue0827/RotationDetection" target="_blank">[KLD-TF], </a>
            <img src="https://img.shields.io/github/stars/open-mmlab/mmrotate?style=social" />
            <a href="https://github.com/open-mmlab/mmrotate" target="_blank">[KLD-PyTorch], </a>
            <img src="https://img.shields.io/github/stars/Jittor/JDet?style=social" />
            <a href="https://github.com/Jittor/JDet" target="_blank">[KLD-Jittor]</a>
          </div>
           <div>
            <img class="responsive-img icon" src="./images/pdf.png">
            <a href="./files/kld_slides.pdf" target="_blank">[slides], </a>
            <a href="./files/neurips21_yx_poster.pdf" target="_blank">[poster]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/zhihu.png">
            <a href="https://zhuanlan.zhihu.com/p/380016283" target="_blank">[Ëß£ËØª], </a>
            <img src="https://img.shields.io/badge/dynamic/json?label=views&style=social&logo=zhihu&query=video.play_count&url=https://www.zhihu.com/api/v4/zvideos/1529579010677370880" />
            <a href="https://www.zhihu.com/zvideo/1529579010677370880" target="_blank">[Áü•‰πéËßÜÈ¢ëËß£ËØª]</a>
          </div>
          <div>
            <!-- <img class="responsive-img icon" src="./images/bilibili.png"> -->
            <img src="https://img.shields.io/badge/dynamic/json?label=views&style=social&logo=bilibili&query=data.stat.view&url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1Wr4y1E7Qr" /></a>
            <a href="https://www.bilibili.com/video/BV1Wr4y1E7Qr" target="_blank">[ËßÜÈ¢ëËß£ËØª]</a>
          </div>
        </div>
      </div>

      <hr class="publication-hr">

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/ril.png">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">Optimization for Arbitrary-Oriented Object Detection via Representation Invariance Loss</div>
        <div class="paper-author">Qi Ming, Lingjuan Miao, Zhiqiang Zhou<sup>‚Ä†</sup>, <font color="#0000dd"><b>Xue Yang</b></font>, Yunpeng Dong</div>
        <div class="paper-conf"><em>IEEE Geoscience and Remote Sensing Letters <font color="red"><b>(GRSL, CCF-C)</b></font></em>, 2021</div> 
        <!-- <div> -->
          <!-- <img class="responsive-img icon" src="./images/pdf.png"> -->
          <a href="https://arxiv.org/abs/2103.11636" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2103.11636-B31B1B.svg" /></a>
          <!-- <a href="https://www.semanticscholar.org/paper/Optimization-for-Arbitrary-Oriented-Object-via-Loss-Ming-Miao/d38b3d1f1d30b7669d991f02065fab9524fc9090" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citations&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fd38b3d1f1d30b7669d991f02065fab9524fc9090%3Ffields%3DcitationCount" /></a> -->
          <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:Wp0gIr-vW9MC" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:Wp0gIr-vW9MC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:Wp0gIr-vW9MC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
        <!-- </div> -->
        <div>
          <!-- <img class="responsive-img icon" src="./images/github.png"> -->
          <img src="https://img.shields.io/github/stars/yangxue0827/RotationDetection?style=social" />
          <a href="https://github.com/yangxue0827/RotationDetection" target="_blank">[RIDet-TF], </a>
          <img src="https://img.shields.io/github/stars/ming71/RIDet?style=social" />
          <a href="https://github.com/ming71/RIDet" target="_blank">[RIDet-PyTorch]</a>
        </div>
      </div>
    </div>

    <hr class="publication-hr">

      <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/sla.png">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">Sparse Label Assignment for Oriented Object Detection in Aerial Images</div>
          <div class="paper-author">Qi Ming,  Lingjuan Miao, Zhiqiang Zhou<sup>‚Ä†</sup>, Junjie Song, <font color="#0000dd"><b>Xue Yang</b></font></div>
          <div class="paper-conf">In <em>Remote Sensing</em>, 2021</div> 
          <div>
            <!-- <a href="https://www.semanticscholar.org/paper/Sparse-Label-Assignment-for-Oriented-Object-in-Ming-Miao/dd1f7e4da3868a4fa42324693f5b20c414bc5b7b" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citations&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fdd1f7e4da3868a4fa42324693f5b20c414bc5b7b%3Ffields%3DcitationCount" /></a> -->
            <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:M3ejUd6NZC8C" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:M3ejUd6NZC8C' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:M3ejUd6NZC8C' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/pdf.png">
            <a href="https://www.mdpi.com/2072-4292/13/14/2664/htm" target="_blank">[paper]</a>
          </div>
          <div>
          <img src="https://img.shields.io/github/stars/ming71/SLA?style=social" />
          <a href="https://github.com/ming71/SLA" target="_blank">[SLA-PyTorch]</a>
        </div>
        </div>
      </div>

      <hr class="publication-hr">

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/gwd.png">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">Rethinking Rotated Object Detection with Gaussian Wasserstein Distance Loss</div>
          <div class="paper-author"><font color="#0000dd"><b>Xue Yang</b></font>, Junchi Yan<sup>‚Ä†</sup>, Qi Ming, Wentao Wang, Xiaopeng Zhang, Qi Tian</div>
          <div class="paper-conf">In <em>International Conference on Machine Learning <font color="red"><b>(ICML, CCF-A)</b></font></em>, Virtual, 2021</div>
          <div>
            <!-- <img class="responsive-img icon" src="./images/pdf.png"> -->
            <a href="https://arxiv.org/abs/2101.11952" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2101.11952-B31B1B.svg" /></a>
            <!-- <a href="https://www.semanticscholar.org/paper/Rethinking-Rotated-Object-Detection-with-Gaussian-Yang-Yan/1b47ee25d1b078368813a417fbe73ceb290e4035" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citations&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F1b47ee25d1b078368813a417fbe73ceb290e4035%3Ffields%3DcitationCount" /></a> -->
            <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:qUcmZB5y_30C" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:qUcmZB5y_30C' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:qUcmZB5y_30C' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
          </div>
          <div>
            <!-- <img class="responsive-img icon" src="./images/github.png"> -->
            <img src="https://img.shields.io/github/stars/yangxue0827/RotationDetection?style=social" />
            <a href="https://github.com/yangxue0827/RotationDetection" target="_blank">[GWD-TF], </a>
            <img src="https://img.shields.io/github/stars/open-mmlab/mmrotate?style=social" />
            <a href="https://github.com/open-mmlab/mmrotate" target="_blank">[GWD-PyTorch], </a>
            <img src="https://img.shields.io/github/stars/Jittor/JDet?style=social" />
            <a href="https://github.com/Jittor/JDet" target="_blank">[GWD-Jittor]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/pdf.png">
            <a href="./files/gwd_slides.pdf" target="_blank">[slides], </a>
            <a href="./files/icml21_yx_poster.pdf" target="_blank">[poster]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/zhihu.png">
            <a href="https://zhuanlan.zhihu.com/p/372357305" target="_blank">[Ëß£ËØª], </a>
            <img src="https://img.shields.io/badge/dynamic/json?label=views&style=social&logo=zhihu&query=video.play_count&url=https://www.zhihu.com/api/v4/zvideos/1529579010677370880" />
            <a href="https://www.zhihu.com/zvideo/1529579010677370880" target="_blank">[Áü•‰πéËßÜÈ¢ëËß£ËØª]</a>
          </div>
          <div>
            <!-- <img class="responsive-img icon" src="./images/bilibili.png"> -->
            <img src="https://img.shields.io/badge/dynamic/json?label=views&style=social&logo=bilibili&query=data.stat.view&url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1Wr4y1E7Qr" /></a>
            <a href="https://www.bilibili.com/video/BV1Wr4y1E7Qr" target="_blank">[ËßÜÈ¢ëËß£ËØª]</a>
          </div>
        </div>
      </div>

      <hr class="publication-hr">

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/dcl.png">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">Dense Label Encoding for Boundary Discontinuity Free Rotation Detection</div>
          <div class="paper-author"><font color="#0000dd"><b>Xue Yang</b></font>, Liping Hou, Yue Zhou, Wentao Wang, Junchi Yan<sup>‚Ä†</sup></div>
          <div class="paper-conf">In <em>Proceedings of the IEEE Computer Vision and Pattern Recognition <font color="red"><b>(CVPR, CCF-A)</b></font></em>, Virtual, 2021</div>
          <div>
            <!-- <img class="responsive-img icon" src="./images/pdf.png"> -->
            <a href="https://arxiv.org/abs/2011.09670" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2011.09670-B31B1B.svg" /></a>
            <!-- <a href="https://www.semanticscholar.org/paper/Dense-Label-Encoding-for-Boundary-Discontinuity-Yang-Hou/729559024cc246c4bb7b33e395d2957b27662eb4" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citations&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F729559024cc246c4bb7b33e395d2957b27662eb4%3Ffields%3DcitationCount" /></a> -->
            <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:9ZlFYXVOiuMC" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:9ZlFYXVOiuMC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:9ZlFYXVOiuMC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
          </div>
          <div>
            <!-- <img class="responsive-img icon" src="./images/github.png"> -->
            <img src="https://img.shields.io/github/stars/Thinklab-SJTU/DCL_RetinaNet_Tensorflow?style=social" />
            <a href="https://github.com/Thinklab-SJTU/DCL_RetinaNet_Tensorflow" target="_blank">[RetinaNet-DCL-TF], </a>
            <img src="https://img.shields.io/github/stars/yangxue0827/RotationDetection?style=social" />
            <a href="https://github.com/yangxue0827/RotationDetection" target="_blank">[R<sup>3</sup>Det-DCL-TF]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/pdf.png">
            <a href="./files/dcl_slides.pdf" target="_blank">[slides], </a>
            <a href="./files/cvpr21_yx_poster.pdf" target="_blank">[poster]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/zhihu.png">
            <a href="https://zhuanlan.zhihu.com/p/354373013" target="_blank">[Ëß£ËØª]</a>
          </div>
        </div>
      </div>

      <hr class="publication-hr">

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/rsdet.png">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">Learning Modulated Loss for Rotated Object Detection</div>
          <div class="paper-author">Wen Qian, <font color="#0000dd"><b>Xue Yang</b></font>, Silong Peng<sup>‚Ä†</sup>, Junchi Yan, Yue Guo</div>
          <div class="paper-conf">In <em>Proceedings of the Thirty-Five AAAI Conference on Artificial Intelligence <font color="red"><b>(AAAI, CCF-A)</b></font></em>, Vancouver, Canada (Virtual), 2021</div>

          <!-- <div> -->
            <!-- <img class="responsive-img icon" src="./images/pdf.png"> -->
            <!-- <a href="https://arxiv.org/abs/1911.08299" target="_blank">paper</a> -->
          <!-- </div> -->
          <div>
            <!-- <img class="responsive-img icon" src="./images/pdf.png"> -->
            <a href="https://arxiv.org/abs/1911.08299" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A1911.08299-B31B1B.svg" /></a>
            <!-- <a href="https://www.semanticscholar.org/paper/Learning-Modulated-Loss-for-Rotated-Object-Qian-Yang/7322a4580299b322223730ca714a0a951788853a" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citations&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F7322a4580299b322223730ca714a0a951788853a%3Ffields%3DcitationCount" /></a> -->
            <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:7PzlFSSx8tAC" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:7PzlFSSx8tAC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:7PzlFSSx8tAC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
          </div>
          <div class="paper-award">
            <img class="responsive-img icon" src="./images/cup.png">
            <a href="https://www.paperdigest.org/2022/02/most-influential-aaai-papers-2022-02/"><em><font color="red"><b>Most Influential AAAI'21 Paper, Top 10</b></font></em></a>
          </div>
          <div>
            <!-- <img class="responsive-img icon" src="./images/github.png"> -->
            <img src="https://img.shields.io/github/stars/yangxue0827/RotationDetection?style=social" />
            <a href="https://github.com/yangxue0827/RotationDetection" target="_blank">[RSDet-TF]</a>
            <img src="https://img.shields.io/github/stars/Jittor/JDet?style=social" />
            <a href="https://github.com/Jittor/JDet" target="_blank">[RSDet-Jittor]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/pdf.png">
            <a href="./files/rsdet_slides.pdf" target="_blank">[slides], </a>
            <a href="./files/aaai_2021_qw_poster.pdf" target="_blank">[poster]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/zhihu.png">
            <a href="https://zhuanlan.zhihu.com/p/108185873" target="_blank">[Ëß£ËØª]</a>
          </div>
        </div>
      </div>

      <hr class="publication-hr">

      <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/r3det.png">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">R<sup>3</sup>Det: Refined Single-Stage Detector with Feature Refinement for Rotating Object</div>
          <div class="paper-author"><font color="#0000dd"><b>Xue Yang</b></font>, Junchi Yan<sup>‚Ä†</sup>, Ziming Feng, Tao He</div>
          <div class="paper-conf">In <em>Proceedings of the Thirty-Five AAAI Conference on Artificial Intelligence <font color="red"><b>(AAAI, CCF-A)</b></font></em>, Vancouver, Canada (Virtual), 2021</div>

          <div>
            <!-- <img class="responsive-img icon" src="./images/pdf.png"> -->
            <a href="https://arxiv.org/abs/1908.05612" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A1908.05612-B31B1B.svg" /></a>
            <!-- <a href="https://www.semanticscholar.org/paper/R3Det%3A-Refined-Single-Stage-Detector-with-Feature-Yang-Liu/edada2363969e3929366df06aad8a8e9c73ba32f" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citations&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fedada2363969e3929366df06aad8a8e9c73ba32f%3Ffields%3DcitationCount" /></a> -->
            <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:Tyk-4Ss8FVUC" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:Tyk-4Ss8FVUC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:Tyk-4Ss8FVUC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
          </div>
          <div class="paper-award">
            <img class="responsive-img icon" src="./images/cup.png">
            <a href="https://www.paperdigest.org/2022/02/most-influential-aaai-papers-2022-02/"><em><font color="red"><b>Most Influential AAAI'21 Paper, Top 1</b></font></em></a>
          </div>
          <div>
            <!-- <img class="responsive-img icon" src="./images/github.png"> -->
            <img src="https://img.shields.io/github/stars/Thinklab-SJTU/R3Det_Tensorflow?style=social" />
            <a href="https://github.com/Thinklab-SJTU/R3Det_Tensorflow" target="_blank">[R<sup>3</sup>Det-TF], </a>
            <!-- <img src="https://img.shields.io/github/stars/SJTU-Thinklab-Det/r3det-on-mmdetection?style=social" />
            <a href="https://github.com/SJTU-Thinklab-Det/r3det-on-mmdetection" target="_blank">[R<sup>3</sup>Det-PyTorch], </a>
            <img src="https://img.shields.io/github/stars/SJTU-Thinklab-Det/r3det-pytorch?style=social" />
            <a href="https://github.com/SJTU-Thinklab-Det/r3det-on-mmdetection" target="_blank">[R<sup>3</sup>Det-PyTorch], </a> -->
            <img src="https://img.shields.io/github/stars/open-mmlab/mmrotate?style=social" />
            <a href="https://github.com/open-mmlab/mmrotate" target="_blank">[R<sup>3</sup>Det-PyTorch]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/pdf.png">
            <a href="./files/r3det_slides.pdf" target="_blank">[slides], </a>
            <a href="./files/aaai_2021_yx_poster.pdf" target="_blank">[poster]</a>
            <a href="http://engine.scichina.com/doi/10.1360/SSI-2022-0410" target="_blank">[ÊúüÂàäÁâàÊú¨„Ää‰∏≠ÂõΩÁßëÂ≠¶Ôºö‰ø°ÊÅØÁßëÂ≠¶„Äã]</a>
          </div>
        </div>
      </div>

      <hr class="publication-hr">

      <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/csl.png">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">Arbitrary-Oriented Object Detection with Circular Smooth Label</div>
          <div class="paper-author"><font color="#0000dd"><b>Xue Yang</b></font>, Junchi Yan<sup>‚Ä†</sup></div>
          <div class="paper-conf">In <em>Proceedings of the European Conference on Computer Vision <font color="red"><b>(ECCV, CCF-B, Tsinghua-A)</b></font></em>, Glasgow, Scotland, UK (Virtual), 2020</div>
          <div>
            <!-- <img class="responsive-img icon" src="./images/pdf.png"> -->
            <a href="https://link.springer.com/chapter/10.1007/978-3-030-58598-3_40" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2003.05597-B31B1B.svg" /></a>
            <!-- <a href="https://www.semanticscholar.org/paper/Arbitrary-Oriented-Object-Detection-with-Circular-Yang-Yan/feb6f9d7082d29dbf4d6c1bb70b404f7237298b6" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citations&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Ffeb6f9d7082d29dbf4d6c1bb70b404f7237298b6%3Ffields%3DcitationCount" /></a> -->
            <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:WF5omc3nYNoC" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:WF5omc3nYNoC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:WF5omc3nYNoC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
          </div>
          <div>
            <!-- <img class="responsive-img icon" src="./images/github.png"> -->
            <img src="https://img.shields.io/github/stars/Thinklab-SJTU/CSL_RetinaNet_Tensorflow?style=social" />
            <a href="https://github.com/Thinklab-SJTU/CSL_RetinaNet_Tensorflow" target="_blank">[CSL-RetinaNet-TF]</a>
            <img src="https://img.shields.io/github/stars/open-mmlab/mmrotate?style=social" />
            <a href="https://github.com/open-mmlab/mmrotate" target="_blank">[CSL-RetinaNet-PyTorch]</a>
            <img src="https://img.shields.io/github/stars/Jittor/JDet?style=social" />
            <a href="https://github.com/Jittor/JDet" target="_blank">[CSL-RetinaNet-Jittor]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/pdf.png">
            <!-- <a href="https://arxiv.org/abs/2003.05597" target="_blank">paper,</a> -->
            <a href="./files/csl_slides.pdf" target="_blank">[slides]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/zhihu.png">
            <a href="https://zhuanlan.zhihu.com/p/111493759" target="_blank">[Ëß£ËØª]</a>
          </div>
        </div>
      </div>

      <hr class="publication-hr">

      <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/scrdet.png">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">SCRDet: Towards More Robust Detection for Small, Cluttered and Rotated Objects</div>
          <div class="paper-author"><font color="#0000dd"><b>Xue Yang</b></font>, Jirui Yang, Junchi Yan<sup>‚Ä†</sup>, Yue Zhang, Tengfei Zhang, Zhi Guo, Sun Xian, Kun Fu</div>
          <div class="paper-conf">In <em>Proceedings of the IEEE International Conference on Computer Vision <font color="red"><b>(ICCV, CCF-A)</b></font></em>, Seoul, Korea, 2019</div>
          <div>
            <!-- <img class="responsive-img icon" src="./images/pdf.png"> -->
            <a href="https://arxiv.org/abs/1811.07126" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A1811.07126-B31B1B.svg" /></a>
            <!-- <a href="https://www.semanticscholar.org/paper/SCRDet%3A-Towards-More-Robust-Detection-for-Small%2C-Yang-Yang/456b8ae5dd6f8316c1fda46c5a8b4204c10ae320" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citations&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F456b8ae5dd6f8316c1fda46c5a8b4204c10ae320%3Ffields%3DcitationCount" /></a> -->
            <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:9yKSN-GCB0IC" target="_blank">
            <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:9yKSN-GCB0IC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:9yKSN-GCB0IC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
          </div>
          <div>
            <!-- <img class="responsive-img icon" src="./images/github.png"> -->
            <img src="https://img.shields.io/github/stars/DetectionTeamUCAS/RetinaNet_Tensorflow_Rotation?style=social" />
            <a href="https://github.com/DetectionTeamUCAS/RetinaNet_Tensorflow_Rotation" target="_blank">[IoU-Smooth L1 Loss-TF],</a>
            <img src="https://img.shields.io/github/stars/DetectionTeamUCAS/R2CNN-Plus-Plus_Tensorflow?style=social" />
            <a href="https://github.com/DetectionTeamUCAS/R2CNN-Plus-Plus_Tensorflow" target="_blank">[R<sup>2</sup>CNN++-TF]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/pdf.png">
            <!-- <a href="https://arxiv.org/abs/1811.07126" target="_blank">paper,</a> -->
            <a href="./files/iccv_2019_yx_poster.pdf" target="_blank">[poster]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/zhihu.png">
            <a href="https://zhuanlan.zhihu.com/p/107400817" target="_blank">[Ëß£ËØª]</a>
          </div>
        </div>
      </div>

      <hr class="publication-hr">

      <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/access.png">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">Position detection and direction prediction for arbitrary-oriented ships via multitask rotation region convolutional neural network</div>
          <div class="paper-author"><font color="#0000dd"><b>Xue Yang</b></font>, Hao Sun, Xian Sun, Menglong Yan, Zhi Guo, Kun Fu<sup>‚Ä†</sup></div>
          <div class="paper-conf">In <em>IEEE Access</em>, 2018</div>
          <div>
            <!-- <a href="https://www.semanticscholar.org/paper/Position-Detection-and-Direction-Prediction-for-via-Yang-Sun/750bc0d2c9105a352001875127d796599a994886" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citations&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F750bc0d2c9105a352001875127d796599a994886%3Ffields%3DcitationCount" /></a> -->
            <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:UeHWp8X0CEIC" target="_blank">
            <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:UeHWp8X0CEIC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:UeHWp8X0CEIC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/pdf.png">
            <a href="https://ieeexplore.ieee.org/abstract/document/8464244" target="_blank">[paper]</a>
          </div>
          <div>
            <img src="https://img.shields.io/github/stars/yangxue0827/R2CNN_HEAD_FPN_Tensorflow?style=social" />
            <a href="https://github.com/yangxue0827/R2CNN_HEAD_FPN_Tensorflow" target="_blank">[R<sup>2</sup>CNN_HEAD_FPN-TF]</a>
          </div>
        </div>
      </div>

      <hr class="publication-hr">

      <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/igarss.png">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">Object Detection With Head Direction in Remote Sensing Images Based on Rotational Region CNN</div>
          <div class="paper-author"><font color="#0000dd"><b>Xue Yang</b></font>, Kun Fu, Hao Sun, Xian Sun, Menglong Yan, Wenhui Diao, Zhi Guo</div>
          <div class="paper-conf">In <em>IEEE International Geoscience and Remote Sensing Symposium <font color="red"><b>(IGARSS)</b></font></em>, 2018</div>
          <div>
            <!-- <a href="https://www.semanticscholar.org/paper/Object-Detection-with-Head-Direction-in-Remote-on-Yang-Fu/812bf76426f7522049882ef6164e67c94a69618c" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citations&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F812bf76426f7522049882ef6164e67c94a69618c%3Ffields%3DcitationCount" /></a> -->
            <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:Y0pCki6q_DkC" target="_blank">
            <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:Y0pCki6q_DkC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:Y0pCki6q_DkC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/pdf.png">
            <a href="https://ieeexplore.ieee.org/document/8518383" target="_blank">[paper]</a>
          </div>
        </div>
      </div>

      <hr class="publication-hr">

      <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/rdfpn.png">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">Automatic Ship Detection in Remote Sensing Images from Google Earth of Complex Scenes Based on Multiscale Rotation Dense Feature Pyramid Networks</div>
          <div class="paper-author"><font color="#0000dd"><b>Xue Yang</b></font>, Hao Sun, Kun Fu<sup>‚Ä†</sup>, Jirui Yang, Xian Sun, Menglong Yan, Zhi Guo</div>
          <div class="paper-conf">In <em>Remote Sensing</em>, 2018</div>
          <div>
            <!-- <img class="responsive-img icon" src="./images/pdf.png"> -->
            <a href="https://arxiv.org/abs/1806.04331" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A1806.04331-B31B1B.svg" /></a>
            <!-- <a href="https://www.semanticscholar.org/paper/Automatic-Ship-Detection-in-Remote-Sensing-Images-Yang-Sun/dad0e3d7b1dc51196255ba220ed58ff29aa7c92b" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citations&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fdad0e3d7b1dc51196255ba220ed58ff29aa7c92b%3Ffields%3DcitationCount" /></a> -->
            <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:bEWYMUwI8FkC" target="_blank">
            <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:bEWYMUwI8FkC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:bEWYMUwI8FkC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
          </div>
          <div class="paper-award">
            <img class="responsive-img icon" src="./images/cup.png">
            <a href="http://apps.webofknowledge.com/"><em><font color="red"><b>ESI Highly Cited Paper</b></font></em></a>
          </div>
          <!-- <div> -->
            <!-- <img class="responsive-img icon" src="./images/pdf.png"> -->
            <!-- <a href="https://www.mdpi.com/2072-4292/10/1/132" target="_blank">paper</a> -->
          <!-- </div> -->
          <div>
            <!-- <img class="responsive-img icon" src="./images/github.png"> -->
            <img src="https://img.shields.io/github/stars/yangxue0827/R-DFPN_FPN_Tensorflow?style=social" />
            <a href="https://github.com/yangxue0827/R-DFPN_FPN_Tensorflow" target="_blank">[R-DFPN-TF]</a>
          </div>
        </div>
      </div>
      <hr class="publication-hr">
      <!-- <div align='right'> <a href="./publications.html" class="more" target="_blank"><i></i> <font color="#A9A9A9" size="2">LEARN MORE>></font> </a></div> -->
  </div>


</div>

<!--==========================================
  Object Detection, Instance Segmentation and Beyond
===========================================-->
<div class="section preprints-section scrollspy" id="ob_and_is">

  <div class="row container">
    <div class="row">
      <div class="title">üìù Object Detection, Instance Segmentation and Beyond</div>
      <hr>
    </div>

  <div class="row">
    <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <img class="responsive-img" src="./images/castdet.png">
    </div>

    <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
      <div class="paper-title">Toward Open Vocabulary Aerial Object Detection with CLIP-Activated Student-Teacher Learning</div>
      <div class="paper-author">Yan Li, Weiwei Guo<sup>‚Ä†</sup>, <font color="#0000dd"><b>Xue Yang</b></font>, Ning Liao, Dunyun He, Jiaqi Zhou, Wenxian Yu</div>
      <div>
        <a href="https://arxiv.org/abs/2311.11646" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2311.11646-B31B1B.svg" /></a>
        <!-- <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&cstart=20&pagesize=80&citation_for_view=2xTlvV0AAAAJ:r0BpntZqJG4C" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:r0BpntZqJG4C' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:r0BpntZqJG4C' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a> -->
      </div>
    </div>
  </div>

  <hr class="publication-hr">

  <div class="row">
    <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <img class="responsive-img" src="./images/efficientmfd.png">
    </div>

    <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
      <div class="paper-title">EfficientMFD: Towards More Efficient Multimodal Synchronous Fusion Detection</div>
      <div class="paper-author">Jiaqing Zhang, Mingxiang Cao, <font color="#0000dd"><b>Xue Yang</b></font>, Weiying Xie, Jie Lei, Daixun Li, Geng Yang, Wenbo Huang, Yunsong Li</div>
      <div>
        <a href="https://arxiv.org/abs/2403.09323" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2403.09323-B31B1B.svg" /></a>
        <!-- <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&cstart=20&pagesize=80&citation_for_view=2xTlvV0AAAAJ:r0BpntZqJG4C" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:r0BpntZqJG4C' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:r0BpntZqJG4C' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a> -->
      </div>
      <div>
          <img src="https://img.shields.io/github/stars/icey-zhang/EfficientMFD?style=social" />
          <a href="https://github.com/icey-zhang/EfficientMFD" target="_blank">[EfficientMFD-PyTorch]</a>
      </div>
    </div>
  </div>

  <hr class="publication-hr">

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/patchdct.png">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">PatchDCT: Patch Refinement for High Quality Instance Segmentation</div>
        <div class="paper-author">Qinrou Wen, Jirui Yang, <font color="#0000dd"><b>Xue Yang</b></font>, Kewei Liang<sup>‚Ä†</sup></div>
        <div class="paper-conf">In <em>International Conference on Learning Representations <font color="red"><b>(ICLR, Tsinghua-A)</b></font></em>, Kigali, Rwanda, 2023</div>
        <div>
          <a href="https://arxiv.org/abs/2302.02693" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2302.02693-B31B1B.svg" /></a>
          <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:YFjsv_pBGBYC" target="_blank">
          <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:YFjsv_pBGBYC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:YFjsv_pBGBYC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
        </div>
        <!-- <div>
          <img class="responsive-img icon" src="./images/pdf.png">
          <a href="https://openreview.net/forum?id=t9Zd7Oi5JPl" target="_blank">[paper]</a>
        </div> -->
        <div>
          <img src="https://img.shields.io/github/stars/olivia-w12/PatchDCT?style=social" />
          <a href="https://github.com/olivia-w12/PatchDCT" target="_blank">[PatchDCT-PyTorch]</a>
        </div>
        <div>
          <img class="responsive-img icon" src="./images/zhihu.png">
          <a href="https://zhuanlan.zhihu.com/p/607624400" target="_blank">[Ëß£ËØª], </a>
          <img src="https://img.shields.io/badge/dynamic/json?label=views&style=social&logo=zhihu&query=video.play_count&url=https://www.zhihu.com/api/v4/zvideos/1622336916027785216" />
          <a href="https://www.zhihu.com/zvideo/1622336916027785216" target="_blank">[Áü•‰πéËßÜÈ¢ëËß£ËØª]</a>
        </div>
        <div>
          <img src="https://img.shields.io/badge/dynamic/json?label=views&style=social&logo=bilibili&query=data.stat.view&url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1Sx4y1w7JK" />
          <a href="https://www.bilibili.com/video/BV1Sx4y1w7JK" target="_blank">[BÁ´ôËßÜÈ¢ëËß£ËØª]</a>
        </div>
      </div>
    </div>

    <hr class="publication-hr">

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/bmvc2019.png">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">Rethinking Classification and Localization for Cascade R-CNN</div>
        <div class="paper-author">Ang Li, <font color="#0000dd"><b>Xue Yang</b></font>, Chongyang Zhang</div>
        <div class="paper-conf">In <em>Proceedings of the 30th British Machine Vision Conference <font color="red"><b>(BMVC, CCF-C)</b></font></em>, Cardiff, Wales, UK, 2019</div>
        <div>
          <!-- <img class="responsive-img icon" src="./images/pdf.png"> -->
          <a href="https://arxiv.org/abs/1907.11914" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A1907.11914-B31B1B.svg" /></a>
          <!-- <a href="https://www.semanticscholar.org/paper/Rethinking-Classification-and-Localization-for-Li-Yang/d92bd7f2c2d83b321b588f32d791122a7396adf7" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citations&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fd92bd7f2c2d83b321b588f32d791122a7396adf7%3Ffields%3DcitationCount" /></a> -->
          <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:kNdYIx-mwKoC" target="_blank">
          <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:kNdYIx-mwKoC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:kNdYIx-mwKoC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
        </div>
      </div>
    </div>

    <hr class="publication-hr">

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/DCMSNN.png">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">A Densely Connected End-to-End Neural Network for Multiscale and Multiscene SAR Ship Detection</div>
        <div class="paper-author">Jiao Jiao, Yue Zhang, Hao Sun, <font color="#0000dd"><b>Xue Yang</b></font>, Xun Gao, Wen Hong, Kun Fu, Xian Sun<sup>‚Ä†</sup></div>
        <div class="paper-conf">In <em>IEEE Access</em>, 2018</div>
        <div>
          <!-- <a href="https://www.semanticscholar.org/paper/A-Densely-Connected-End-to-End-Neural-Network-for-Jiao-Zhang/11272cb9f1f5921741803e0a5b9c7d9bc4d5f7bc" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citations&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F11272cb9f1f5921741803e0a5b9c7d9bc4d5f7bc%3Ffields%3DcitationCount" /></a> -->
          <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:u5HHmVD_uO8C" target="_blank">
          <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:u5HHmVD_uO8C' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:u5HHmVD_uO8C' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
        </div>
        <div class="paper-award">
          <img class="responsive-img icon" src="./images/cup.png">
          <a href="http://apps.webofknowledge.com/"><em><font color="red"><b>ESI Highly Cited Paper</b></font></em></a>
        </div>
        <div>
          <img class="responsive-img icon" src="./images/pdf.png">
          <a href="https://ieeexplore.ieee.org/abstract/document/8334534" target="_blank">[paper]</a>
        </div>
      </div>
    </div>

    <hr class="publication-hr">


  </div>

</div>


<!--==========================================
    Scene Text Detection and Recognition
===========================================-->
<div class="section preprints-section scrollspy" id="ocr">

  <div class="row container">
    <div class="row">
      <div class="title">üìù Scene Text Detection and Recognition</div>
      <hr>
    </div>

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/ccd.png">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">Self-supervised Character-to-Character Distillation for Text Recognition</div>
        <div class="paper-author">Tongkun Guan, Wei Shen<sup>‚Ä†</sup>, <font color="#0000dd"><b>Xue Yang</b></font>, Qi Feng, Zekun Jiang, Xiaokang Yang</div>
        <div class="paper-conf">In <em>Proceedings of the IEEE International Conference on Computer Vision <font color="red"><b>(ICCV, CCF-A)</b></font></em>, Paris, France, 2023</div>
        <div>
          <a href="https://arxiv.org/abs/2211.00288" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2111.06677-B31B1B.svg" /></a>
          <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:GnPB-g6toBAC" target="_blank">
          <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:GnPB-g6toBAC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:GnPB-g6toBAC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
        </div>
        <div>
            <img src="https://img.shields.io/github/stars/TongkunGuan/CCD?style=social" />
            <a href="https://github.com/TongkunGuan/CCD" target="_blank">[CCD-PyTorch]</a>
        </div>
        <div>
            <img class="responsive-img icon" src="./images/zhihu.png">
            <a href="https://zhuanlan.zhihu.com/p/644350078" target="_blank">[Ëß£ËØª]</a>
        </div>
      </div>
    </div>

    <hr class="publication-hr">

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/gten.png">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">Self-supervised Implicit Glyph Attention for Text Recognition</div>
        <div class="paper-author">Tongkun Guan, Chaochen Gu<sup>‚Ä†</sup>, Jingzheng Tu, <font color="#0000dd"><b>Xue Yang</b></font>, Qi Feng, Yudi Zhao, Wei Shen<sup>‚Ä†</sup></div>
        <div class="paper-conf">In <em>Proceedings of the IEEE Computer Vision and Pattern Recognition <font color="red"><b>(CVPR, CCF-A)</b></font></em>, Vancouver, Canada, 2023</div> 
        <div>
          <a href="https://arxiv.org/abs/2203.03382" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2203.03382-B31B1B.svg" /></a>
          <!-- <a href="https://www.semanticscholar.org/paper/A-Glyph-driven-Topology-Enhancement-Network-for-Guan-Gu/1eb445c6ccb839002b22d6ba05a6d3a83aac8372" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citations&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F1eb445c6ccb839002b22d6ba05a6d3a83aac8372%3Ffields%3DcitationCount" /></a> -->
          <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&citation_for_view=2xTlvV0AAAAJ:isC4tDSrTZIC" target="_blank">
          <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:isC4tDSrTZIC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:isC4tDSrTZIC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
        </div>
        <div>
          <img src="https://img.shields.io/github/stars/TongkunGuan/SIGA?style=social" />
          <a href="https://github.com/TongkunGuan/SIGA" target="_blank">[SIGA-PyTorch]</a>
        </div>
        <div>
          <img class="responsive-img icon" src="./images/zhihu.png">
          <a href="https://zhuanlan.zhihu.com/p/644350078" target="_blank">[Ëß£ËØª]</a>
        </div>
      </div>
    </div>

  <hr class="publication-hr">


  </div>

</div>


<!--==========================================
                Low-Level Vision
===========================================-->
<div class="section preprints-section scrollspy" id="low_level">

  <div class="row container">
    <div class="row">
      <div class="title">üìù Low-Level Vision</div>
      <hr>
    </div>

  <div class="row">
    <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <img class="responsive-img" src="./images/wwt_cvpr22.jpg">
    </div>

    <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
      <div class="paper-title">Dual-path Image Inpainting with Auxiliary GAN Inversion</div>
      <div class="paper-author">Wentao Wang, Li Niu<sup>‚Ä†</sup>, Jianfu Zhang, <font color="#0000dd"><b>Xue Yang</b></font>, Liqing Zhang<sup>‚Ä†</sup></div>
      <div class="paper-conf">In <em>Proceedings of the IEEE Computer Vision and Pattern Recognition <font color="red"><b>(CVPR, CCF-A)</b></font></em>, New Orleans, Louisiana, USA, 2022</div> 
      <div>
        <!-- <a href="https://www.semanticscholar.org/paper/Dual-path-Image-Inpainting-with-Auxiliary-GAN-Wang-Niu/9e93ea471ade297fa55d836241428e2174d43fbe" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citations&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F9e93ea471ade297fa55d836241428e2174d43fbe%3Ffields%3DcitationCount" /></a> -->
        <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&cstart=20&pagesize=80&citation_for_view=2xTlvV0AAAAJ:r0BpntZqJG4C" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:r0BpntZqJG4C' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:r0BpntZqJG4C' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
      </div>
      <div>
        <img class="responsive-img icon" src="./images/pdf.png">
        <a href="https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Dual-Path_Image_Inpainting_With_Auxiliary_GAN_Inversion_CVPR_2022_paper.html" target="_blank">[paper], </a>
        <a href="./files/cvpr22_inp_poster.pdf" target="_blank">[poster]</a>
    </div>
    </div>
  </div>

  <hr class="publication-hr">

  <div class="row">
    <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <img class="responsive-img" src="./images/pmrfnet.jpeg">
    </div>

    <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
      <div class="paper-title">Parallel Multi-Resolution Fusion Network for Image Inpainting</div>
      <div class="paper-author">Wentao Wang, Jianfu Zhang, Li Niu<sup>‚Ä†</sup>, Haoyu Ling, <font color="#0000dd"><b>Xue Yang</b></font>, Liqing Zhang<sup>‚Ä†</sup></div>
      <div class="paper-conf">In <em>Proceedings of the IEEE International Conference on Computer Vision <font color="red"><b>(ICCV, CCF-A)</b></font></em>, Virtual, 2021</div>
      <div>
        <!-- <a href="https://www.semanticscholar.org/paper/Parallel-Multi-Resolution-Fusion-Network-for-Image-Wang-Zhang/320335cd05e98089de35057348498000d3130429" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citations&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F320335cd05e98089de35057348498000d3130429%3Ffields%3DcitationCount" /></a> -->
        <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2xTlvV0AAAAJ&cstart=20&pagesize=80&citation_for_view=2xTlvV0AAAAJ:mVmsd5A6BfQC" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="88" height="20" role="img"><linearGradient id="s" x2="0" y2="100%"><stop offset="0" stop-color="#bbb" stop-opacity=".1"/><stop offset="1" stop-opacity=".1"/></linearGradient><clipPath id="r"><rect width="88" height="20" rx="3" fill="#fff"/></clipPath><g clip-path="url(#r)"><rect width="51" height="20" fill="#555"/><rect x="51" width="37" height="20" fill="#007ec6"/><rect width="88" height="20" fill="url(#s)"/></g><g fill="#fff" text-anchor="middle" font-family="Verdana,Geneva,DejaVu Sans,sans-serif" text-rendering="geometricPrecision" font-size="110"><text aria-hidden="true" x="265" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)" textLength="410">citations</text><text x="265" y="140" transform="scale(.1)" fill="#fff" textLength="410">citations</text><text class='show_paper_citations' data='2xTlvV0AAAAJ:mVmsd5A6BfQC' aria-hidden="true" x="685" y="150" fill="#010101" fill-opacity=".3" transform="scale(.1)"></text><text class='show_paper_citations' data='2xTlvV0AAAAJ:mVmsd5A6BfQC' x="685" y="140" transform="scale(.1)" fill="#fff"></text></g></svg></a>
      </div> 
      <div>
        <img class="responsive-img icon" src="./images/pdf.png">
        <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Wang_Parallel_Multi-Resolution_Fusion_Network_for_Image_Inpainting_ICCV_2021_paper.pdf" target="_blank">[paper], </a>
        <a href="./files/iccv21_wwt_poster.pdf" target="_blank">[poster]</a>
      </div>
    </div>
  </div>

  <hr class="publication-hr">


  </div>

</div>

<!--==========================================
                   Footer
===========================================-->
<footer class="page-footer grey lighten-2">
    <div class="row">
      <div class="widgetContainer" style="width:300px; margin: 0 auto;">        
        <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=080808&w=300&t=tt&d=yZcblN50sSwsCOVmEPYqkPD6Wo-RFHx0E2yb6Ktm_Wk&co=ffffff&ct=808080&cmo=3acc3a&cmn=ff5353'></script>
      </div>
    </div>
    <div class="footer-copyright center black-text">
      Copyright ¬© Xue Yang 2020
    </div>  
</footer>

<!--  Scripts-->
<script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js"></script>
<script src="./files/materialize.js"></script>
<script src="./files/aos.js"></script>
<script src="./init.js"></script>
<script>
    window.onload = function () {
    // $(document).ready(function () {
        var gsDataBaseUrl = 'https://raw.githubusercontent.com/yangxue0827/yangxue0827.github.io/'
        $.getJSON(gsDataBaseUrl + "google-scholar-stats/gs_data.json", function (data) {

            //var totalCitation = data['citedby']
            //document.getElementById('total_cit').innerHTML = totalCitation;
            var citationEles = document.getElementsByClassName('show_paper_citations')
            Array.prototype.forEach.call(citationEles, element => {
                var paperId = element.getAttribute('data')
                var numCitations = data['publications'][paperId]['num_citations']
                element.innerHTML = numCitations;
            });
        });
    }
</script>

</div><div class="jvectormap-tip"></div></body></html>